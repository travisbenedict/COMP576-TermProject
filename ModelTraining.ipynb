{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the data. All of it is in train folder right now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading and Formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import os\n",
    "\n",
    "path_to_train = 'data/train'\n",
    "glob_train_imgs = os.path.join(path_to_train, '*_sat.jpg')\n",
    "glob_train_masks = os.path.join(path_to_train, '*_msk.png')\n",
    "\n",
    "train_img_paths = glob(glob_train_imgs)\n",
    "train_mask_paths = glob(glob_train_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from skimage.color import rgb2gray\n",
    "import cv2\n",
    "\n",
    "# This will be useful so we can construct the corresponding mask\n",
    "def get_img_id(img_path):\n",
    "    img_basename = os.path.basename(img_path)\n",
    "    img_id = os.path.splitext(img_basename)[0][:-len('_sat')]\n",
    "    return img_id\n",
    "\n",
    "# Create image generator and preform preprocessing\n",
    "def image_gen(img_paths, img_size=(512, 512), train=True):\n",
    "    # Iterate over all the image paths\n",
    "    for img_path in img_paths:\n",
    "        \n",
    "        # Construct the corresponding mask path\n",
    "        img_id = get_img_id(img_path)\n",
    "        \n",
    "        # Normalize it to 0-1 range\n",
    "        img = img / 255.  \n",
    "        ##############################\n",
    "        \n",
    "        # Get mask information for train data\n",
    "        if train:\n",
    "            mask_path = os.path.join(path_to_train, img_id + '_msk.png')\n",
    "            mask = rgb2gray(imread(mask_path))\n",
    "#             mask = resize(mask, img_size, mode='constant', preserve_range=True)\n",
    "            # Turn the mask back into a 0-1 mask\n",
    "            mask = (mask >= 0.5).astype(float)\n",
    "            \n",
    "            # Yield the image mask pair\n",
    "            yield img, mask\n",
    "            \n",
    "        else:\n",
    "            yield img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metric Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend.tensorflow_backend as K\n",
    "from keras.losses import binary_crossentropy\n",
    "\n",
    "smooth = 1e-9\n",
    "\n",
    "# This is the competition metric implemented using Keras\n",
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred = K.cast(y_pred, 'float32')\n",
    "    y_pred_f = K.cast(K.greater(K.flatten(y_pred), 0.5), 'float32')\n",
    "    intersection = y_true_f * y_pred_f\n",
    "    score = 2. * (K.sum(intersection) + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "    return score\n",
    "\n",
    "# We'll construct a Keras Loss that incorporates the DICE score\n",
    "def dice_loss(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return 1. - (2. * intersection + 1.) / (K.sum(y_true_f) + K.sum(y_pred_f) + 1.)\n",
    "\n",
    "\n",
    "def bce_dice_loss(y_true, y_pred):\n",
    "    return 0.5 * binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.Session(config=config)\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict\n",
    "import multiprocessing\n",
    "from keras.models import load_model\n",
    "\n",
    "model = load_model(filepath, custom_objects={\"dice_coef\": dice_coef})\n",
    "\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "\n",
    "path_to_test = 'data/val'\n",
    "glob_test_imgs = os.path.join(path_to_test, '*_sat.jpg')\n",
    "\n",
    "test_img_paths = glob(glob_test_imgs)\n",
    "\n",
    "testgen = test_batch_generator(test_img_paths)\n",
    "\n",
    "# Steps is the number of batches to compute results for\n",
    "test_masks = model.predict_generator(testgen, steps=calc_steps(len(test_img_paths), BATCHSIZE), verbose=1)\n",
    "# test_masks = model.predict_generator(testgen, steps=calc_steps(len(test_img_paths), BATCHSIZE), workers=num_cores, use_multiprocessing=True, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source for the pretrained UNet model:\n",
    "    https://www.kaggle.com/kmader/data-preprocessing-and-unet-segmentation-gpu"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
