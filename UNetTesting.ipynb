{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading and Formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from skimage.color import rgb2gray\n",
    "import cv2\n",
    "import itertools\n",
    "\n",
    "# This will be useful so we can construct the corresponding mask\n",
    "def get_img_id(img_path):\n",
    "    img_basename = os.path.basename(img_path)\n",
    "    img_id = os.path.splitext(img_basename)[0][:-len('_sat')]\n",
    "    return img_id\n",
    "\n",
    "# Create image generator and preform preprocessing\n",
    "def image_gen(img_paths, mask_paths=[], img_size=(384, 384), train=True):\n",
    "    # Iterate over all the image paths\n",
    "    for img_path, mask_path in itertools.zip_longest(img_paths, mask_paths):\n",
    "        \n",
    "        # Load image and sharpen\n",
    "        img = imread(img_path)\n",
    "        img = resize(img, img_size)\n",
    "        # Normalize it to 0-1 range\n",
    "#         img = img / 255.0.  \n",
    "        ##############################\n",
    "        \n",
    "        # Get mask information for train data\n",
    "        if train:\n",
    "            mask = rgb2gray(imread(mask_path))\n",
    "            # Turn the mask back into a 0-1 mask\n",
    "            mask = (mask >= 0.5).astype(float)\n",
    "            \n",
    "            # Yield the image mask pair\n",
    "            yield img, mask\n",
    "            \n",
    "        else:\n",
    "            yield img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metric Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras.backend.tensorflow_backend as K\n",
    "from keras.losses import binary_crossentropy\n",
    "\n",
    "smooth = 1e-9\n",
    "\n",
    "# This is the competition metric implemented using Keras\n",
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred = K.cast(y_pred, 'float32')\n",
    "    y_pred_f = K.cast(K.greater(K.flatten(y_pred), 0.5), 'float32')\n",
    "    intersection = y_true_f * y_pred_f\n",
    "    score = 2. * (K.sum(intersection) + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "    return score\n",
    "\n",
    "# We'll construct a Keras Loss that incorporates the DICE score\n",
    "def dice_loss(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return 1. - (2. * intersection + 1.) / (K.sum(y_true_f) + K.sum(y_pred_f) + 1.)\n",
    "\n",
    "\n",
    "def bce_dice_loss(y_true, y_pred):\n",
    "    return 0.5 * binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:186: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 384, 384, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 384, 384, 3)  12          input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 384, 384, 3)  0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 384, 384, 8)  224         dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 384, 384, 8)  584         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 192, 192, 8)  0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 192, 192, 16) 1168        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 192, 192, 16) 2320        conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 96, 96, 16)   0           conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 96, 96, 32)   4640        max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 96, 96, 32)   9248        conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 48, 48, 32)   0           conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 48, 48, 64)   18496       max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 48, 48, 64)   36928       conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 24, 24, 64)   0           conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 24, 24, 128)  73856       max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 24, 24, 128)  147584      conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTrans (None, 48, 48, 64)   32832       conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 48, 48, 128)  0           conv2d_transpose_1[0][0]         \n",
      "                                                                 conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 48, 48, 64)   73792       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 48, 48, 64)   36928       conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTrans (None, 96, 96, 32)   8224        conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 96, 96, 64)   0           conv2d_transpose_2[0][0]         \n",
      "                                                                 conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 96, 96, 32)   18464       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 96, 96, 32)   9248        conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTrans (None, 192, 192, 16) 2064        conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 192, 192, 32) 0           conv2d_transpose_3[0][0]         \n",
      "                                                                 conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 192, 192, 16) 4624        concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 192, 192, 16) 2320        conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTrans (None, 384, 384, 8)  520         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 384, 384, 16) 0           conv2d_transpose_4[0][0]         \n",
      "                                                                 conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 384, 384, 8)  1160        concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 384, 384, 8)  584         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 384, 384, 1)  9           conv2d_18[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 485,829\n",
      "Trainable params: 485,823\n",
      "Non-trainable params: 6\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, BatchNormalization, Dropout, Lambda\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.merge import concatenate\n",
    "\n",
    "# IMG_SIZE = (512, 512)\n",
    "IMG_SIZE = (384, 384)\n",
    "\n",
    "# Build U-Net model\n",
    "inputs = Input(IMG_SIZE+(3,))\n",
    "s = BatchNormalization()(inputs) # we can learn the normalization step\n",
    "s = Dropout(0.5)(s)\n",
    "\n",
    "c1 = Conv2D(8, (3, 3), activation='relu', padding='same') (s)\n",
    "c1 = Conv2D(8, (3, 3), activation='relu', padding='same') (c1)\n",
    "p1 = MaxPooling2D((2, 2)) (c1)\n",
    "\n",
    "c2 = Conv2D(16, (3, 3), activation='relu', padding='same') (p1)\n",
    "c2 = Conv2D(16, (3, 3), activation='relu', padding='same') (c2)\n",
    "p2 = MaxPooling2D((2, 2)) (c2)\n",
    "\n",
    "c3 = Conv2D(32, (3, 3), activation='relu', padding='same') (p2)\n",
    "c3 = Conv2D(32, (3, 3), activation='relu', padding='same') (c3)\n",
    "p3 = MaxPooling2D((2, 2)) (c3)\n",
    "\n",
    "c4 = Conv2D(64, (3, 3), activation='relu', padding='same') (p3)\n",
    "c4 = Conv2D(64, (3, 3), activation='relu', padding='same') (c4)\n",
    "p4 = MaxPooling2D(pool_size=(2, 2)) (c4)\n",
    "\n",
    "c5 = Conv2D(128, (3, 3), activation='relu', padding='same') (p4)\n",
    "c5 = Conv2D(128, (3, 3), activation='relu', padding='same') (c5)\n",
    "\n",
    "u6 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same') (c5)\n",
    "u6 = concatenate([u6, c4])\n",
    "c6 = Conv2D(64, (3, 3), activation='relu', padding='same') (u6)\n",
    "c6 = Conv2D(64, (3, 3), activation='relu', padding='same') (c6)\n",
    "\n",
    "u7 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c6)\n",
    "u7 = concatenate([u7, c3])\n",
    "c7 = Conv2D(32, (3, 3), activation='relu', padding='same') (u7)\n",
    "c7 = Conv2D(32, (3, 3), activation='relu', padding='same') (c7)\n",
    "\n",
    "u8 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same') (c7)\n",
    "u8 = concatenate([u8, c2])\n",
    "c8 = Conv2D(16, (3, 3), activation='relu', padding='same') (u8)\n",
    "c8 = Conv2D(16, (3, 3), activation='relu', padding='same') (c8)\n",
    "\n",
    "u9 = Conv2DTranspose(8, (2, 2), strides=(2, 2), padding='same') (c8)\n",
    "u9 = concatenate([u9, c1], axis=3)\n",
    "c9 = Conv2D(8, (3, 3), activation='relu', padding='same') (u9)\n",
    "c9 = Conv2D(8, (3, 3), activation='relu', padding='same') (c9)\n",
    "\n",
    "outputs = Conv2D(1, (1, 1), activation='sigmoid') (c9)\n",
    "\n",
    "model = Model(inputs=[inputs], outputs=[outputs])\n",
    "model.compile(optimizer='adam', loss=dice_loss, metrics=[dice_coef])\n",
    "model.summary()\n",
    "\n",
    "session = tf.Session(graph=model.output.graph, config=config)\n",
    "K.set_session(session) \n",
    "init = K.tf.global_variables_initializer() \n",
    "K.get_session().run(init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch generator function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Keras takes its input in batches \n",
    "# (i.e. a batch size of 32 would correspond to 32 images and 32 masks from the generator)\n",
    "# The generator should run forever\n",
    "def image_batch_generator(img_paths, mask_paths, batchsize=32):\n",
    "    while True:\n",
    "        ig = image_gen(img_paths, mask_paths)\n",
    "        batch_img, batch_mask = [], []\n",
    "        \n",
    "        for img, mask in ig:\n",
    "            # Add the image and mask to the batch\n",
    "            batch_img.append(img)\n",
    "            mask = resize(mask, (384, 384, 1)) # Reshape masks to be (512, 512, 1)\n",
    "            batch_mask.append(mask)\n",
    "            # If we've reached our batchsize, yield the batch and reset\n",
    "            if len(batch_img) == batchsize:\n",
    "                yield np.stack(batch_img, axis=0), np.stack(batch_mask, axis=0)\n",
    "                batch_img, batch_mask = [], []\n",
    "        \n",
    "        # If we have an nonempty batch left, yield it out and reset\n",
    "        if len(batch_img) != 0:\n",
    "            yield np.stack(batch_img, axis=0), np.stack(batch_mask, axis=0)\n",
    "            batch_img, batch_mask = [], []\n",
    "            \n",
    "            \n",
    "def test_batch_generator(img_paths, batchsize=32):\n",
    "    while True:\n",
    "        ig = image_gen(img_paths, train=False)\n",
    "        batch_img = []\n",
    "        \n",
    "        for img in ig:\n",
    "            # Add the image and mask to the batch\n",
    "            batch_img.append(img)\n",
    "            # If we've reached our batchsize, yield the batch and reset\n",
    "            if len(batch_img) == batchsize:\n",
    "                yield np.stack(batch_img, axis=0)\n",
    "                batch_img = []\n",
    "        \n",
    "        # If we have an nonempty batch left, yield it out and reset\n",
    "        if len(batch_img) != 0:\n",
    "            yield np.stack(batch_img, axis=0)\n",
    "            batch_img = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "filepath = \"TrainedUNet.hdf5\"\n",
    "model.load_weights(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_steps(data_len, batchsize):\n",
    "    return (data_len + batchsize - 1) // batchsize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import multiprocessing\n",
    "from glob import glob\n",
    "BATCHSIZE = 50\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "\n",
    "path_to_test = 'data/test'\n",
    "glob_test_imgs = os.path.join(path_to_test, '*_sat.jpg')\n",
    "glob_test_masks = os.path.join(path_to_test, '*_msk.png')\n",
    "\n",
    "test_img_paths = sorted(glob(glob_test_imgs))\n",
    "test_mask_paths = sorted(glob(glob_test_masks))\n",
    "\n",
    "evaluate_gen = image_batch_generator(test_img_paths, test_mask_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/engine/training_generator.py:293: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\n",
      "  UserWarning('Using a generator with `use_multiprocessing=True`'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - 34s 1s/step\n"
     ]
    }
   ],
   "source": [
    "# Steps is the number of batches to compute results for\n",
    "\n",
    "\n",
    "metrics = model.evaluate_generator(evaluate_gen, steps=calc_steps(len(test_img_paths), BATCHSIZE),\n",
    "                                     workers=num_cores, use_multiprocessing=True, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss', 'dice_coef']\n",
      "[0.4448719855510827, 0.5551677237857472]\n"
     ]
    }
   ],
   "source": [
    "print(model.metrics_names)\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "testgen = test_batch_generator(test_img_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/engine/training_generator.py:398: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\n",
      "  UserWarning('Using a generator with `use_multiprocessing=True`'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - 32s 977ms/step\n"
     ]
    }
   ],
   "source": [
    "predicted_masks = model.predict_generator(testgen, steps=calc_steps(len(test_img_paths), BATCHSIZE),\n",
    "                                     workers=num_cores, use_multiprocessing=True, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predicted_masks' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-ba2f35126a72>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mminP\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mmaxP\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'predicted_masks' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "minP = np.min(predicted_masks)\n",
    "maxP = np.max(predicted_masks)\n",
    "\n",
    "for i in range(10):\n",
    "    pred_mask = predicted_masks[i] \n",
    "    \n",
    "    normed_pred_mask = (predicted_masks[i] - minP) / (maxP-minP)\n",
    "    normed_pred_mask = normed_pred_mask.reshape(384, 384)\n",
    "    im = plt.imread(test_img_paths[i])\n",
    "    true_mask = plt.imread(test_mask_paths[i])\n",
    "    depool_mask = plt.imread(\"DePoolNetPredMask/DePoolNetPredMask{}.png\".format(i))\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 4, figsize=(32,32))\n",
    "    axes[0].imshow(im)\n",
    "    axes[1].imshow(normed_pred_mask, plt.cm.gray)\n",
    "    axes[2].imshow(depool_mask, plt.cm.gray)\n",
    "    axes[3].imshow(true_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Convolutional Filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_filter_images(layer, inps, result_dir, name):\n",
    "    acts_filters = tf.unstack(layer, axis=3)\n",
    "    with tf.name_scope(name):\n",
    "        for i, filter in enumerate(acts_filters):\n",
    "            b = tf.summary.image('filter' + str(i), tf.expand_dims(filter, axis=3) , max_outputs=len(inps))\n",
    "            summary_writer.add_summary(b.eval(feed_dict={inputs:inps}), 0)\n",
    "        summary_writer.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(1)\n",
    "samp = random.sample(range(0,len(test_img_paths)), 10)\n",
    "\n",
    "inps = np.array([resize(plt.imread(test_img_paths[i]), (384,384)) for i in samp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First layer complete\n",
      "Second layer complete\n"
     ]
    }
   ],
   "source": [
    "result_dir = './resultsUnet/'\n",
    "# Instantiate a SummaryWriter to output summaries and the Graph.\n",
    "summary_writer = tf.summary.FileWriter(result_dir, session.graph)\n",
    "with session.as_default():\n",
    "    generate_filter_images(c1, inps, result_dir, \"UNet_First_Layer_Weights\")\n",
    "    print(\"First layer complete\")\n",
    "    generate_filter_images(c2, inps, result_dir, \"UNet_Second_Layer_Weights\")\n",
    "    print(\"Second layer complete\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
